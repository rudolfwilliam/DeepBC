"""Custom dataset of CelebA with continuous attributes as generated by classifiers."""

from deepbc.celeba.data.meta_data import attrs, vars2int, attr2int
from torch.utils.data import Dataset
from torchvision.datasets import CelebA
from torchvision.transforms import Resize, ToTensor, Normalize, CenterCrop, Compose, ConvertImageDtype
import torch

DATA_PATH = "./celeba/data"
MEANS_PATH = "./celeba/data/predictions/means.pt"
STDS_PATH = "./celeba/data/predictions/stds.pt"

def load_data():
    transforms = Compose([CenterCrop(150), Resize((128, 128)), ToTensor(), ConvertImageDtype(dtype=torch.float32), Normalize(mean=[0., 0., 0.], std=[1., 1., 1.]),])
    data = CelebA(root=DATA_PATH, split='all', transform=transforms, download=True)
    return data

def load_statistics():
    means = torch.load(MEANS_PATH)
    stds = torch.load(STDS_PATH)
    return means, stds

class Statistics(object):
    def __init__(self):
        self.means, self.stds = load_statistics()

    def standardize(self, attr, val):
        return (val - self.means[attr]) / self.stds[attr]
    
    def destandardize(self, attr, val):
        # loaded data is standardized
        return val * self.stds[attr] + self.means[attr]

class CelebaDiscrete(Dataset):
    def __init__(self, transform=None, as_dict=False):
        super().__init__()
        self.transform = transform
        self.as_dict = as_dict
        self.data = load_data()
        self.attr = torch.stack([torch.stack([self.data.attr[idx][attr2int[attr]] for attr in attr2int.keys()], dim=0) for idx in range(len(self.data.attr))])

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        if self.transform:
            return self.transform(self.data[idx][0], self.attr[idx])
        if self.as_dict:
            return {**{attr : self.attr[idx][vars2int[attr]].view(1, -1) for attr in attrs}, "image" : self.data[idx][0].unsqueeze(0)}
        return self.data[idx][0], self.attr[idx]
    
class CelebaContinuous(Dataset):
    def __init__(self, cont_attr_path="./celeba/data/predictions/preds.pt", transform=None, as_dict=False):
        super().__init__()
        self.transform = transform
        self.as_dict = as_dict
        self.data = load_data()
        self.cont_attr = torch.load(cont_attr_path)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        if self.transform:
            return self.transform(self.data[idx][0], self.cont_attr[idx])
        if self.as_dict:
            return {**{attr : self.cont_attr[idx][vars2int[attr]].view(1, -1) for attr in attrs}, "image" : self.data[idx][0].unsqueeze(0)}
        return self.data[idx][0], self.cont_attr[idx]
    
    def standardize(self, attr, val):
        return (val - self.means[attr]) / self.stds[attr]
    
    def destandardize(self, attr, val):
        # loaded data is standardized
        return val * self.stds[attr] + self.means[attr]

# Custom transform to only select attributes
class SelectAttributesTransform:
    def __init__(self, attr_idx, pa_idx):
        self.attr_idx = attr_idx
        self.pa_idx = pa_idx

    def __call__(self, img, attrs):
        return attrs[[self.attr_idx]], torch.Tensor([attrs[idx] for idx in self.pa_idx])
